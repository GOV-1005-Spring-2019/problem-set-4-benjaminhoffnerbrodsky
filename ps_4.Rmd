---
title: "Problem Set 4"
author: "Benjamin Hoffner-Brodsky"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Setting include to false so that non-technical writers only see the relevant output
#without the code, warning messages, or any other distracting elements

#Importing and cleaning packages

library(janitor)
library(readxl)

#Enables git installs to install the gt package

library(devtools)

#Data and time tools

library(lubridate)

#Table visualization package

library(gt)

#Preset visual elements package to supplement ggplot2 within the tidyverse

library(ggthemes)

#Primary package group for all data manipulation and visualization 

#Note that this is loaded last so as not to be masked by any other packages

library(tidyverse)

#Reading in data from the project directory

#Note that the data must already be loaded into the directory before running

#Data accessed via Gov 1005 GitHub classroom 

#This section is intended to create generally tidy data that will be useful for 
#answering all four questions

orig <- read_csv("ps_4_elections-poll-nc09-3.csv",
                 
#Assigning data types to columns

#The program runs fine without this, but will spit out a series of warning messages 
#otherwise

              col_types = cols(
                
                .default = col_character(),
                
                turnout_scale = col_double(),
                
                turnout_score = col_double(),
                
                w_LV = col_double(),
                
                w_RV = col_double(),
                
                final_weight = col_double(),
                
                timestamp = col_datetime(format = "")
                
              )) %>% 
  
#Converts column names to tidy names -- those with lower caps and spaces replaced 
#by "_"

#This is important to avoid the challenges related to having column names with spaces
#and to create a cleaner and more consistent style 
  
  clean_names() %>%
  
#Filters out data that is missing the field of interest

#Note that in an earlier commit this section instead used a %in% operator to check
#if response was within the set of responses we're interested in (Dem, Rep, Und),
#however further investigation into the NYT chart revealed that they chose to include
#responses marked "3" when calculating the total even though they weren't included
#as a field in the table, so the line was changed to just remove NA values
  
  filter(!is.na(response), 
         
         !is.na(race_eth), 
         
         !is.na(final_weight),
         
         educ != "[DO NOT READ] Refused") 

#Replacing all response values of "3" with the string "three"

#This is done to avoid challenges associated with having a variable that is just a number, even
#if formatted as a string 

orig$response[orig$response == "3"] <- "three"

#This section is intended to transform the data into a format that will be optimal 
#for visualizing as a chart in question 2

table_data <- orig %>% 
  
#Selecting for just the variables of interest in the table

#This is necessary because spread will rearrange all of the data in a dataframe,
#meaning that excess data should be trimmed first
  
  select(response, race_eth, final_weight) %>% 
  
#Initially grouping by both race and response in order to calculate summary statistics
#for each subset

#This created too many rows which will be resolved by spread() later
  
  group_by(response, race_eth) %>% 
  
#Creating total, the count of weights for each race/response pair

#Note that the final_weights are being sum, rather than counting the observations,
#to account for the divergent rates at which groups respond to polls

#Summarize is used over mutate because total is now the only data that is needed
  
  summarize(total = sum(final_weight, na.rm = TRUE)) %>% 
  
#Rearranges the data, grouping by the response value to create the new column names of
#Dem, Rep, and Und. Value = total indicates that the totals will become the new row
#observations
  
  spread(key = response, value = total) %>%
  
#Ungrouping ends the above group_by, which is no longer relevant because of the spread
  
#This should be done before regrouping for a new variable below, to avoid a nested group
  
  ungroup() %>% 
  
#Grouping by race to mutate each total as a percentage
  
  group_by(race_eth) %>% 
  
#Calculating the sum of all responses as an intermediary step before converting the totals
#to percentages in the next step
#Note that three is included here which will result in some rows not adding up to 100%
  
#Also note that this is a situtation which the variables are called without using quotation
#marks, which means that if not for the above step in which 3 was replaced with three, sum
#would be adding the number 3 here, rather than the variable it refers to
  
#Finally note that na.rm is set to TRUE, which is critical because the Asian row has no 
#responses maked Und, resulting in an NA in that column

#If na.rm were not set to true, then adding Und with an NA value would set all equal to NA
#for the Asian row which would then make Dem and Rep also NA in the next step 

  mutate(all = sum(Dem, Rep, Und, three, na.rm = TRUE)) %>% 
  
#Uses the all value to recalculate each observation as a percentage 
  
  mutate(Dem = Dem / all,
         
         Rep = Rep / all,
         
         Und = Und / all) %>%
  
#Ungrouping to prepare for functions that are operating on the whole table
  
  ungroup() %>% 
  
#Selecting out the now vestigial all value to prepare for gt()
  
  select(race_eth, Dem, Rep, Und) %>% 
  
#Slicing the race column not to filter out any variables, but to reorder them into the 
#desired arrangement 
  
  slice(match(c("White", "Black", "Hispanic", "Asian", "Other"), race_eth)) 

#Creating a new variable that counts the number of each kind of response for questions 1.1 and 1.2

response_counts <- orig %>% 
  
  group_by(response) %>% 
  
  summarize(n())

#Creating a new varable that lists the timestamps of dem responses in ascending order for question 1.5

dem_dates <- orig %>% 
  
  filter(response == "Dem") %>% 
  
  select(timestamp) %>% 
  
  arrange(timestamp)

#Creating a new variable that lists the timestamps of rep responses in ascending order for question 1.5 

rep_dates <- orig %>% 
  
  filter(response == "Rep") %>% 
  
  select(timestamp) %>% 
  
  arrange(timestamp)

```
## Question 1

There were `r response_counts[1, 2]` respondents who supported the Democratic candidate.

There were `r response_counts[2, 2] - response_counts[4, 2]` more respondents who favored the Republican candidate than who were Undecided.

There are two gender variables (`gender` and `gender_combined`). There are `r orig %>% filter(gender != gender_combined) %>% summarize(n())` individuals for whom these variables have different values.

There are `r orig %>% filter(race_eth == "White", file_race_black != "White") %>% summarize(n())` respondents listed as “White” under `race_eth` who are not listed as “White” under `file_race_black`.

The first `response` of Dem came `r round(as.numeric(rep_dates[1,1] - dem_dates[1,1]), digits = 0)` minutes (rounded to the nearest minute) before the first `response` of Dem.

## Question 2

```{r table_plot, echo = FALSE, warning = FALSE, results = "asis"}
#Setting results to "asis" to prepare for plotting a table

#Initiating table function

gt(table_data) %>% 
  
#Renaming column labels to match those of the NYT
  
  cols_label(
    
    Dem = "DEM.",
    
    Rep = "REP.",
    
    Und = "UND.",

    race_eth = ""
    
    ) %>% 
  

  fmt_missing(columns = vars(Und), rows = 4) %>% 
  fmt_percent(columns = vars(Dem, Rep, Und), decimals = 0) %>% 
  tab_style(style = cells_styles(bkgd_color = "#fbfafb", text_color = "#666666"), locations = cells_data()) %>%
  tab_style(style = cells_styles(bkgd_color = "#ffffff", text_color = "#666666"), locations = cells_data(columns = 1)) %>%
  tab_style(style = cells_styles(bkgd_color = "#dd0d27", text_color = "#ffffff"), locations = cells_data(columns = 3, rows = 1)) %>% 
  tab_style(style = cells_styles(bkgd_color = "#dd0d27", text_color = "#ffffff"), locations = cells_data(columns = 3, rows = 3)) %>%
  tab_style(style = cells_styles(bkgd_color = "#dd0d27", text_color = "#ffffff"), locations = cells_data(columns = 3, rows = 4)) %>% 
  tab_style(style = cells_styles(bkgd_color = "#0089c6", text_color = "#ffffff"), locations = cells_data(columns = 2, rows = 2)) %>% 
  tab_style(style = cells_styles(bkgd_color = "#0089c6", text_color = "#ffffff"), locations = cells_data(columns = 2, rows = 5)) %>% 
  tab_header(title = "Party Preferences by Race in North Carolina's 9th") %>% 
  tab_source_note(source_note = "Source: New York Times Upshot") %>% 
  as_raw_html() %>% 
  as.character() %>% 
  cat()
            
```

## Question 3

```{r violin_plot, echo = FALSE, warning = FALSE}

ggplot(orig, aes(x = educ, y = final_weight)) +
  geom_violin() +
  geom_jitter(alpha = 0.4, width = 0.2, size = 0.9) +
  coord_flip() +
  scale_x_discrete(limits=c("Grade school", "High school","Some college or trade school", "Bachelors' degree", "Graduate or Professional Degree")) +
  xlab(NULL) +
  ylab("Weight Given to Respondent in Calculating Poll Results") +
  labs(
    title = "More Educated Matter Less in North Carolina 9th",
    subtitle = "Poll gives more weight to people who are less likely to participate in polls",
    caption = "New York Times Upshot/Siena College 2018 live polls"
  )

```

## Question 4

```{r categorical_plot}

```

## Colleagues

Hemanth Bharatha Chakravarthy and Dasha Met
